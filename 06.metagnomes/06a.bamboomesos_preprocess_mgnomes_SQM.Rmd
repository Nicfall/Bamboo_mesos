---
title: "Bamboo mesocosms experiment - squeezemeta analysis"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
 rmarkdown::html_document:
    theme: cerulean
    toc: yes
    toc_float: yes
    highlight: haddock
    number_sections: true
editor_options: 
  chunk_output_type: console
---

# Per sample raw reads

```{bash, eval=F}
for file in *.fastq.gz
do
  echo $file > 
  zcat $file.fastq.gz | wc -l
  
#!/bin/bash

# Output file
output="mgs_raw_read_counts.tsv"
echo -e "Sample\tR1_reads\tR2_reads" > $output

# Get list of unique sample names (before _R1 or _R2)
for sample in $(ls *_R1_*.fastq.gz | sed 's/_R1_.*.fastq.gz//' | sort | uniq); do
    # Find R1 and R2 file paths
    R1_file=$(ls ${sample}_R1_*.fastq.gz)
    R2_file=$(ls ${sample}_R2_*.fastq.gz)

    # Count reads
    R1_count=$(zcat "$R1_file" | wc -l)
    R2_count=$(zcat "$R2_file" | wc -l)

    # Divide by 4 to get number of reads
    R1_reads=$((R1_count / 4))
    R2_reads=$((R2_count / 4))

    # Write to file
    echo -e "${sample}\t${R1_reads}\t${R2_reads}" >> $output
done
```

# Databases

Normally I would follow the [squeezemeta installation instructions](https://github.com/jtamames/SqueezeMeta), but Samira already downloaded the databases into a directory, so just making a copy of my own from there.

```{bash, eval=F}
cd /home/nicolagk/cmaiki_koastore/fatemi/DATABASES
```

Text within nk_copy.slurm:

```
#!/bin/bash
#SBATCH --job-name=nk_copy.slurm
#SBATCH --partition=shared
##3 day max run time for public partitions, except 4 hour max runtime for the sandbox partition
#SBATCH --time=0-72:00:00
#SBATCH --nodes=1
#SBATCH --cpus-per-task=10
#SBATCH --mem=100G
#SBATCH --error=%A.err
#SBATCH --output=%A.out ##%A = filled with job id
#SBATCH --mail-type=BEGIN,END,FAIL,REQUEUE,TIME_LIMIT_80
#SBATCH --mail-user=nicolagk@hawaii.edu

cp -r ./db /home/nicolagk/cmaiki_koastore/nicolagk/bamboomesos_metagnomes/squeeze
```
Save & exit, submit:

```{bash, eval=F}
sbatch nk_copy.slurm
```

Note: the actual bro5 metagenome results were also in the db folder, so those got copied over, will delete later

# Setting up squeeze meta

```{bash, eval=F}
##conda doesn't work unless I do this first:
srun -p sandbox -N 1 -c 1 --mem=6G -t 0-01:00:00 --pty /bin/bash

ml lang/Anaconda3
conda --version ##24.4.0

module list
##Currently Loaded Modules:
#  1) lang/Anaconda3/2024.02-1

##installation following instructions from the squeeze meta github:
conda install -n base conda-libmamba-solver
##output notes:
#Channels:
# - defaults
# - conda-forge
#Platform: linux-64

##ERROR:
#EnvironmentNotWritableError: The current user does not have write permissions to the target environment.
#  environment location: /opt/apps/software/lang/Anaconda3/2024.02-1
#  uid: 7033
#  gid: 7033

##^even though I got that error, the rest of this still worked:
conda config --set solver libmamba
##no errors on that one
conda create -n SqueezeMeta -c conda-forge -c bioconda -c fpusan squeezemeta=1.6 --no-channel-priority --override-channels
##says it will try to install a million packages
##not seeing any errors, but it does say this:
```

```
Krona installed.  You still need to manually update the taxonomy                
databases before Krona can generate taxonomic reports.  The update              
script is ktUpdateTaxonomy.sh.  The default location for storing                
taxonomic databases is /home/nicolagk/.conda/envs/SqueezeMeta/opt/krona/taxonomy
                                                                                
If you would like the taxonomic data stored elsewhere, simply replace           
this directory with a symlink.  For example:                                    
                                                                                
rm -rf /home/nicolagk/.conda/envs/SqueezeMeta/opt/krona/taxonomy                
mkdir /path/on/big/disk/taxonomy                                                
ln -s /path/on/big/disk/taxonomy /home/nicolagk/.conda/envs/SqueezeMeta/opt/krona/taxonomy                                                                      
ktUpdateTaxonomy.sh 

##end of text:                                                                               
# To activate this environment, use                                             
#                                                                               
#     $ conda activate SqueezeMeta
#
# To deactivate an active environment, use
#
#     $ conda deactivate
```

I didn't do any of the suggestions about Krona (yet). Script that checks whether things are working:

```{bash, eval=F}
##note: sometimes I have to run this interactively before running conda activate:
#source activate base

conda activate SqueezeMeta

##what version
SqueezeMeta.pl -v 
#1.6.5.post1, November 2024

##change where the databases are:
perl /home/nicolagk/.conda/envs/SqueezeMeta/SqueezeMeta/utils/install_utils/configure_nodb.pl /home/nicolagk/cmaiki_koastore/nicolagk/bamboomesos_metagnomes/squeeze/db

##test:
test_install.pl
```

Getting errors about "kmer-db", but according to [this issue page](https://github.com/jtamames/SqueezeMeta/issues/741) I likely don't need this program unless I was doing "seqmerge" mode (one of the assembly strategies)

# Running the pipeline

## Testing with just 3 samples

Text within sqm_bamboomesos_3samps.slurm

```
#!/bin/bash
#SBATCH --job-name=sqm_bamboomesos_3samps
#SBATCH --partition=exclusive-long
#SBATCH --time=7-00:00:00 ## time format is DD-HH:MM:SS
#SBATCH --nodes=4
#SBATCH --error=job%A.err ## %A - filled with jobid
#SBATCH --output=job%A.out ## %A - filled with jobid
#SBATCH --mail-type=BEGIN,END,FAIL,REQUEUE,TIME_LIMIT_80
#SBATCH --mail-user=nicolagk@hawaii.edu

ml lang/Anaconda3
source activate SqueezeMeta
SqueezeMeta.pl -m sequential -s /home/nicolagk/cmaiki_koastore/nicolagk/bamboomesos_metagnomes/3samps/file.names_3samps -f /home/nicolagk/cmaiki_koastore/nicolagk/bamboomesos_metagnomes/3samps --cleaning --nobins
```

Notes: -f is the directory where the .fastq.gz files are, -s is a text file that looks like this:

```
LB5	LB5_S15_L001_R1_001.fastq.gz	pair1
LB5	LB5_S15_L001_R2_001.fastq.gz	pair2
LL11	LL11_S6_L001_R1_001.fastq.gz	pair1
LL11	LL11_S6_L001_R2_001.fastq.gz	pair2
WB9	WB9_S10_L001_R1_001.fastq.gz	pair1
WB9	WB9_S10_L001_R2_001.fastq.gz	pair2
```

Another note: check that "--cleaning" is actually 2 short hyphens and not one long one, or it won't clean the reads

### Array option

```{bash, eval=F}
#!/bin/bash
#SBATCH --job-name=3samps_array
#SBATCH --partition=exclusive-long
#SBATCH --time=7-00:00:00  ## Format: DD-HH:MM:SS
#SBATCH --nodes=2
#SBATCH --array=1-3  ## Replace 'M' with the number of unique samples (not file lines!)
#SBATCH --error=job%A_%a.err  ## Job ID (%A), Task ID (%a)
#SBATCH --output=job%A_%a.out  ## Job ID (%A), Task ID (%a)
#SBATCH --mail-type=BEGIN,END,FAIL,REQUEUE,TIME_LIMIT_80
#SBATCH --mail-user=nicolagk@hawaii.edu

## Load environment
ml lang/Anaconda3
source activate SqueezeMeta

## Define paths
SAMPLE_LIST=/home/nicolagk/cmaiki_koastore/nicolagk/bamboomesos_metagnomes/3samps/sample_list.txt  ## Contains just unique sample names: LB5, LL11, WB9...
FULL_SAMPLE_FILE=/home/nicolagk/cmaiki_koastore/nicolagk/bamboomesos_metagnomes/3samps/file.names_3samps  ## Contains the paired-end file structure

## Get the sample name for this task
SAMPLE=$(sed -n "${SLURM_ARRAY_TASK_ID}p" "${SAMPLE_LIST}")

## Extract corresponding lines for this sample
grep -P "^${SAMPLE}\t" "${FULL_SAMPLE_FILE}" > "sample_${SAMPLE}.txt"

## Run SqueezeMeta on the extracted sample file
SqueezeMeta.pl -m sequential -s "sample_${SAMPLE}.txt" -f /home/nicolagk/cmaiki_koastore/nicolagk/bamboomesos_metagnomes/3samps --cleaning --nobins -t 20

```

## More than 3 samps

Above was just 3 samples, but I have many more. First, this script makes the formatted sample list file which is nice:

```{bash, eval=F}
for file in *_R1_001.fastq.gz; do base=$(echo "$file" | sed -E 's/_S[0-9]+_L001_R1_001.fastq.gz//'); echo -e "$base\t$file\tpair1"; echo -e "$base\t${file/_R1_/_R2_}\tpair2"; done > formatted_samples.tsv
```

Next I need the unique sample names for the array script:

```{bash, eval=F}
ls *.fastq.gz | cut -d'_' -f1 | sort -u > unique_samples.txt
```

Now the array script is the same as above, but there are 45 samples now

### Array option

```{bash, eval=F}
nano mostsamps_array.slurm
```

Text within:

```
#!/bin/bash
#SBATCH --job-name=mostsamps_array
#SBATCH --partition=exclusive
#SBATCH --time=3-00:00:00  ## Format: DD-HH:MM:SS
#SBATCH --nodes=5
#SBATCH --array=1-45%5  ## Replace 'M' with the number of unique samples (not file lines!)
#SBATCH --error=job%A_%a.err  ## Job ID (%A), Task ID (%a)
#SBATCH --output=job%A_%a.out  ## Job ID (%A), Task ID (%a)
#SBATCH --mail-type=BEGIN,END,FAIL,REQUEUE,TIME_LIMIT_80
#SBATCH --mail-user=nicolagk@hawaii.edu

## Load environment
ml lang/Anaconda3
source activate SqueezeMeta

## Define paths
SAMPLE_LIST=/home/nicolagk/cmaiki_koastore/nicolagk/bamboomesos_metagnomes/all_fastqs/unique_samples.txt  ## Contains just unique sample names: LB5, LL11, WB9...
FULL_SAMPLE_FILE=/home/nicolagk/cmaiki_koastore/nicolagk/bamboomesos_metagnomes/all_fastqs/formatted_samples.tsv  ## Contains the paired-end file structure

## Get the sample name for this task
SAMPLE=$(sed -n "${SLURM_ARRAY_TASK_ID}p" "${SAMPLE_LIST}")

## Extract corresponding lines for this sample
grep -P "^${SAMPLE}\t" "${FULL_SAMPLE_FILE}" > "sample_${SAMPLE}.txt"

## Run SqueezeMeta on the extracted sample file
SqueezeMeta.pl -m sequential -s "sample_${SAMPLE}.txt" -f /home/nicolagk/cmaiki_koastore/nicolagk/bamboomesos_metagnomes/all_fastqs --cleaning --nobins -t 20
```

# Packaging results for R

```{bash, eval=F}
srun -p sandbox -N 1 -c 1 --mem=6G -t 0-01:00:00 --pty /bin/bash

ml lang/Python
ml lang/Anaconda3
##note: sometimes I have to run this before running conda activate:
source activate base
conda activate SqueezeMeta
```

## Slurm script version

```{bash, eval=F}
nano sqm2zip.slurm
```

```
#!/bin/bash
#SBATCH --job-name=sqm2zip
#SBATCH --partition=shared
##3 day max run time for public partitions, except 4 hour max runtime for the sandbox partition
#SBATCH --time=0-72:00:00
#SBATCH --nodes=1
#SBATCH --cpus-per-task=10
#SBATCH --mem=100G
#SBATCH --error=%A.err
#SBATCH --output=%A.out ##%A = filled with job id
#SBATCH --mail-type=BEGIN,END,FAIL,REQUEUE,TIME_LIMIT_80
#SBATCH --mail-user=nicolagk@hawaii.edu

ml lang/Anaconda3
source activate SqueezeMeta

output_dir="./rready"

for dir in $(ls | grep -E '^(LB|LL|WB|WL)[0-9]+$'); do
    echo "Processing $dir"
    python /home/nicolagk/.conda/envs/SqueezeMeta/bin/sqm2zip.py $dir $output_dir
done
```

# Script ends here

# Reading SQM results into R

## Setup

```{r}
#BiocManager::install("SQMtools")
library("SQMtools")

##3 samples test runs:
#setwd("~/nicolagk@hawaii.edu - Google Drive/My Drive/Bamboo_mesos/metagenomes/SQM_zips_3samps")

##real deal:
setwd("~/nicolagk@hawaii.edu - Google Drive/My Drive/Bamboo_mesos/metagenomes/SQM_zips")
```

## Doing it

```{r}
# Define the directory containing the .zip files
##tests:
#zip_dir <- "~/nicolagk@hawaii.edu - Google Drive/My Drive/Bamboo_mesos/metagenomes/SQM_zips_3samps"

##real deal:
zip_dir <- "~/nicolagk@hawaii.edu - Google Drive/My Drive/Bamboo_mesos/metagenomes/SQM_zips"

# Get a list of all .zip files
zip_files <- list.files(zip_dir, pattern = "\\.zip$", full.names = TRUE)
head(zip_files)

# Loop through each .zip file
for (zip_file in zip_files){
  # Extract the base name (without extension) to use as the object name
  obj_name <- tools::file_path_sans_ext(basename(zip_file))
  # Assign the result of loadSQM() to a variable with the extracted name
  assign(obj_name, loadSQM(zip_file), envir = .GlobalEnv)
}

##selecting my R objects that start with these 2 capital letters
object_names <- ls(pattern = "^[LW]")

for (obj in object_names) {
  # Construct the new variable name
  new_name <- paste0(obj, ".bac")
  # Print the name for debugging
  print(paste("Creating:", new_name))
  # Use get() to retrieve the actual object
  obj_data <- get(obj)
  # Apply the function to the object
  result <- subsetTax(obj_data, "superkingdom", "Bacteria")
  # Assign the result to a new variable with the dynamically created name
  assign(new_name, result, envir = .GlobalEnv)
}

# Get all objects that end with ".bac" (matching our dynamically created ones)
bac_objects <- ls(pattern = "\\.bac$")

# Retrieve the actual objects using mget()
bac_list <- mget(bac_objects)

# Combine them into one using combineSQMlite()
bactab.3samps <- do.call(combineSQMlite, bac_list)



```



# Full tables

```{r}
library("SQMtools")

setwd("~/nicolagk@hawaii.edu - Google Drive/My Drive/Bamboo_mesos/metagenomes")
```

## Bacteria

```{r}
bactab.all <- readRDS("bactab.all.rds")

bactab.ks <- data.frame(bactab.all[["functions"]][["KEGG"]][["abund"]])
bactab.knames <- data.frame(bactab.all[["misc"]][["KEGG_names"]])
##rename the column
colnames(bactab.knames) <- c("KEGG_names")
##remove kegg names that aren't in our data frame
bactab.knames.inc <- bactab.knames[row.names(bactab.knames) %in% row.names(bactab.ks),]

setdiff(row.names(bactab.ks), row.names(bactab.knames))  # Rows in bactab.ks but not in bactab.knames
setdiff(row.names(bactab.knames), row.names(bactab.ks))  # Rows in bactab.knames but not in bactab.ks

write.csv(bactab.ks)

##checking out just one example
lb5.bac.ks <- data.frame(lb5.bac[["functions"]][["KEGG"]][["abund"]])
lb5.bac.knames <- data.frame(lb5.bac[["misc"]][["KEGG_names"]])

setdiff(row.names(lb5.bac.ks), row.names(lb5.bac.knames))  # Rows in bactab.ks but not in bactab.knames
setdiff(row.names(lb5.bac.knames), row.names(lb5.bac.ks))  # Rows in bactab.knames but not in bactab.ks

setdiff(row.names(lb5.bac.ks), row.names(bactab.ks[,"LB5",drop=F]))
setdiff(row.names(bactab.ks[,"LB5",drop=F]), row.names(lb5.bac.ks))

bactab.ks.lb5 <- bactab.ks[!is.na(bactab.ks[,"LB5"]) & bactab.ks[,"LB5"] != 0, ]
lb5.bac.ks.no0 <- lb5.bac.ks[!is.na(lb5.bac.ks[,"LB5", drop=F]) & lb5.bac.ks[,"LB5", drop=F] != 0,,drop=F]

#bactab.ks.lb5 <- bactab.ks[bactab.ks[,"LB5"]!=0,]
setdiff(row.names(bactab.ks.lb5), row.names(lb5.bac.ks.no0))
setdiff(row.names(lb5.bac.ks.no0), row.names(bactab.ks.lb5))

#bactab.ks.lb5[,"LB5"] == lb5.bac.ks.no0
##supposed to check if any don't match
any(bactab.ks.lb5[,"LB5"] != lb5.bac.ks.no0) 
```

I don't know why, but there are lots of gaps in the full bacteria table of the full kegg names, so going to do it this way instead:

```{r}
download.file("https://rest.kegg.jp/list/ko", "kegg_ko_list.txt")

lines <- readLines("kegg_ko_list.txt")
length(lines)
kegg_data <- read.delim("kegg_ko_list.txt", header = FALSE, sep = "\t", quote = "", stringsAsFactors = FALSE)

colnames(kegg_data) <- c("KEGG_ID", "Description")

bactab.kegg <- data.frame(KEGG_ID=row.names(bactab.ks))

bactab.kegg.info <- merge(bactab.kegg,kegg_data,by="KEGG_ID")

setdiff(bactab.kegg.info$KEGG_ID, row.names(bactab.ks))
setdiff(row.names(bactab.ks), bactab.kegg.info$KEGG_ID)


setdiff(bactab.kegg$KEGG_ID, row.names(bactab.ks))


# Example: Find the name for "K18069"
kegg_data[kegg_data$KEGG_ID == "ko:K18069", ]

row.names(bactab.ks)

#write.csv(bactab.kegg.info,"bactab.allsamps.kegg.info.csv")
#write.csv(bactab.ks,"bactab.allsamps.counts.csv")

keggpaths.all <- data.frame(paths=bactab.all[["misc"]][["KEGG_paths"]])
library(stringr)

paths.split <- data.frame(str_split_fixed(keggpaths.all$paths, pattern="; ",n=17))
paths.split[56,]
keggpaths.all[56,]

keggpaths.all.split1 <- cbind(keggpaths.all,paths.split)

keggpaths.all.split <- cbind(KEGG_ID = rownames(keggpaths.all.split1), keggpaths.all.split1)

#write.csv(keggpaths.all.split,"bactab.allsamps.keggpaths.csv")

```

```{r}
library("SQMtools")

setwd("~/nicolagk@hawaii.edu - Google Drive/My Drive/Bamboo_mesos/metagenomes/SQM_zips_3samps")

#LB5 <- readRDS("LB5.rds")
#WB9 <- readRDS("WB9.rds")
#LL11 <- readRDS("LL11.rds")

lb5 <- loadSQM("LB5.zip")
wb9 <- loadSQM("WB9.zip")
ll11 <- loadSQM("LL11.zip")

lb5.bac <- subsetTax(lb5, "superkingdom", "Bacteria")
wb9.bac <- subsetTax(wb9, "superkingdom", "Bacteria")
ll11.bac <- subsetTax(ll11, "superkingdom", "Bacteria")

bactab.3samps <- combineSQMlite(lb5.bac,wb9.bac,ll11.bac)
bactab.3samps


lb5.kpaths <- data.frame(paths=lb5.bac[["misc"]][["KEGG_paths"]])
lb5.kinfo <- data.frame(paths=lb5.bac[["misc"]][["KEGG_names"]])

head(lb5.kinfo[!row.names(lb5.kinfo) %in% row.names(lb5.kpaths),,drop=F])
any(row.names(lb5.kinfo) != row.names(lb5.kpaths))

lb5.bac.counts <- lb5.bac[["functions"]][["KEGG"]][["abund"]]

head(lb5.bac.counts[!row.names(lb5.bac.counts) %in% row.names(lb5.kpaths),,drop=F])

pathlist.3samps <- bactab.3samps[["misc"]][["KEGG_paths"]]
pathlist.lb5 <- lb5.bac[["misc"]][["KEGG_paths"]]

head(pathlist.3samps)
head(pathlist.3samps)

head(lb5.kinfo[!pathlist.3samps %in% row.names(lb5.kpaths),,drop=F])

pathlist.lb5.unique <- unique(pathlist.lb5)
pathlist.lb5.names.unique <- unique(names(pathlist.lb5))

```

Doing this on the cluster because it's toooo many entries

```{r}

kegg.paths <- readRDS("~/Downloads/KEGG_paths_list.rds")

# Initialize an empty data frame
unique_paths_df <- data.frame(KO = character(), Pathway = character(), stringsAsFactors = FALSE)

# Loop through each sample in kegg.paths
for (sample in names(kegg.paths)) {
  # Extract the named vector of pathways (KO IDs are names)
  pathways_list <- kegg.paths[[sample]]
  
  # Loop through each KO entry
  for (ko in names(pathways_list)) {
    # Get the pathway string and split into individual pathways
    split_paths <- unlist(strsplit(pathways_list[[ko]], "; ", fixed = TRUE))
    
    # Create a temporary dataframe for this KO
    temp_df <- data.frame(KO = ko, Pathway = unique(split_paths), stringsAsFactors = FALSE)
    
    # Combine with the main dataframe
    unique_paths_df <- rbind(unique_paths_df, temp_df)
  }
}

# Remove duplicates in case the same KO-pathway pair appears multiple times
unique_paths_df <- unique(unique_paths_df)

# View the table
print(unique_paths_df)

# Save to CSV if needed
write.csv(unique_paths_df, "unique_kegg_paths_with_KO.csv", row.names = FALSE)

```

# Back in R

```{r}
library("SQMtools")

setwd("~/nicolagk@hawaii.edu - Google Drive/My Drive/Bamboo_mesos/metagenomes/SQM_zips")

bac.counts <- read.csv("bactab.allsamps.counts.csv",row.names=1)
kegg.paths <- read.csv("unique_kegg_paths_with_KO.csv")
kegg.names <- read.csv("unique_kegg_names_with_KO.csv")
colnames(kegg.names) <- c("KO","names")

##they all match
any(kegg.paths$KO != kegg.names$KO)

bac.kos <- row.names(bac.counts)

kegg.paths.kos <- kegg.paths[kegg.paths$KO %in% bac.kos,]
kegg.names.kos <- kegg.names[kegg.names$KO %in% bac.kos,]

kegg.infos <- merge(kegg.names.kos,kegg.paths.kos,by="KO")

#write.csv(kegg.infos,file="bactab.kegginfos.csv")
```

# Fungi? 

```{r}
library("SQMtools")

setwd("~/nicolagk@hawaii.edu - Google Drive/My Drive/Bamboo_mesos/metagenomes/SQM_zips_3samps")

#LB5 <- readRDS("LB5.rds")
#WB9 <- readRDS("WB9.rds")
#LL11 <- readRDS("LL11.rds")

lb5 <- loadSQM("LB5.zip")
wb9 <- loadSQM("WB9.zip")
ll11 <- loadSQM("LL11.zip")

wb9.fungi <- subsetTax(wb9, "phylum", c("Ascomycota", "Basidiomycota", "Chytridiomycota","Microsporidia", "Mucoromycota", "Zoopagomycota", "Olpidiomycota"))

fungal_phyla <- c("Ascomycota", "Basidiomycota", "Chytridiomycota","Microsporidia", "Mucoromycota", "Zoopagomycota", "Olpidiomycota")

wb9.fungi <- do.call(rbind, lapply(fungal_phyla, function(phy) {
  subsetTax(wb9, "phylum", phy)
}))
lb5.fun1 <- subsetTax(wb9, "phylum", "Ascomycota")
lb5.fun1 <- subsetTax(wb9, "phylum", "Basidiomycota")

fungal_phyla <- c("Ascomycota", "Basidiomycota", "Chytridiomycota","Microsporidia", "Mucoromycota", "Zoopagomycota", "Olpidiomycota")

subsetTaxMulti = function (SQM, rank, taxa,
                           trusted_functions_only = FALSE,
                           ignore_unclassified_functions = FALSE, 
                           rescale_tpm = TRUE,
                           rescale_copy_number = TRUE)
    {
    subs = lapply(taxa, FUN=function(tax) subsetTax(SQM, rank, tax, trusted_functions_only, ignore_unclassified_functions, rescale_tpm, rescale_copy_number))
    return(combineSQM(subs, tax_source = "contigs", trusted_functions_only = trusted_functions_only, ignore_unclassified_functions = ignore_unclassified_functions, rescale_tpm = rescale_tpm, rescale_copy_number = rescale_copy_number))
}

wb9.fun <- subsetTaxMulti(wb9,"phylum",fungal_phyla)

#### HERE? ####
LB5 <- loadSQM("LB5.zip")
WB9 <- loadSQM("WB9.zip")
LL11 <- loadSQM("LL11.zip")

# List objects that start with "L" or "W"
object_names <- ls(pattern = "^[LW]")

# Define the list of fungal phyla
fungal_phyla <- c("Ascomycota", "Basidiomycota", "Chytridiomycota", "Microsporidia", "Mucoromycota", "Zoopagomycota", "Olpidiomycota")

# List objects that start with "L" or "W"
object_names <- ls(pattern = "^[LW]")

# Define the list of fungal phyla
fungal_phyla <- c("Ascomycota", "Basidiomycota", "Chytridiomycota", 
                  "Microsporidia", "Mucoromycota", "Zoopagomycota", "Olpidiomycota")

for (obj in object_names) {
  # Construct the new variable name
  new_name <- paste0(obj, ".fun")
  # Retrieve the object
  obj_data <- get(obj)
  # Extract phylum names from the SQM structure
  existing_phyla <- rownames(obj_data[["taxa"]][["phylum"]]$abun)  # Extract row names (phylum names)
  # Find which fungal phyla are present
  valid_fungal_phyla <- intersect(fungal_phyla, existing_phyla)
  # Print debugging information
  print(paste("Processing:", obj, "→", new_name))
  print(paste("Valid phyla found:", paste(valid_fungal_phyla, collapse = ", ")))
  # Only proceed if there are valid fungal phyla
  if (length(valid_fungal_phyla) > 0) {
    result <- subsetTaxMulti(obj_data, "phylum", valid_fungal_phyla)
  } else {
    result <- NULL  # Or handle empty cases differently
    message(paste("No fungal phyla found in", obj))
  }
  
  # Assign result to a new variable
  assign(new_name, result, envir = .GlobalEnv)
}



#lb5.euk <- subsetTax(lb5, "superkingdom", "Eukaryota")
#wb9.euk <- subsetTax(wb9, "superkingdom", "Eukaryota")
#ll11.euk <- subsetTax(ll11, "superkingdom", "Eukaryota")

euktab.3samps <- combineSQMlite(lb5.euk,wb9.euk,ll11.euk)


setwd("/mnt/lustre/koa/koastore/cmaiki_group/nicolagk/bamboomesos_metagnomes/mostsamps/rready/rproc")

euktab <- readRDS("euktab.allsamps.rds")
euk.phyla <- euktab[["taxa"]][["phylum"]][["abun"]]
names(euk.phyla)

tax.phyla <- euktab[["taxa"]][["phylum"]][["abund"]]
row.names(tax.phyla)
write.table(row.names(tax.phyla),file="tax.phyla.txt")

```

On cluster:

```{r}
library("SQMtools")

setwd("/mnt/lustre/koa/koastore/cmaiki_group/nicolagk/bamboomesos_metagnomes/mostsamps/rready/fun_proc")
zip_dir <- "/mnt/lustre/koa/koastore/cmaiki_group/nicolagk/bamboomesos_metagnomes/mostsamps/rready/fun_proc"


subsetTaxMulti = function (SQM, rank, taxa,
                           trusted_functions_only = FALSE,
                           ignore_unclassified_functions = FALSE, 
                           rescale_tpm = TRUE,
                           rescale_copy_number = TRUE)
    {
    subs = lapply(taxa, FUN=function(tax) subsetTax(SQM, rank, tax, trusted_functions_only, ignore_unclassified_functions, rescale_tpm, rescale_copy_number))
    return(combineSQM(subs, tax_source = "contigs", trusted_functions_only = trusted_functions_only, ignore_unclassified_functions = ignore_unclassified_functions, rescale_tpm = rescale_tpm, rescale_copy_number = rescale_copy_number))
}

zip_dir <- "~/nicolagk@hawaii.edu - Google Drive/My Drive/Bamboo_mesos/metagenomes/SQM_zips_3samps"

##real deal:
#zip_dir <- "~/nicolagk@hawaii.edu - Google Drive/My Drive/Bamboo_mesos/metagenomes/SQM_zips"

# Get a list of all .zip files
zip_files <- list.files(zip_dir, pattern = "\\.zip$", full.names = TRUE)
head(zip_files)

# Loop through each .zip file
for (zip_file in zip_files){
  # Extract the base name (without extension) to use as the object name
  obj_name <- tools::file_path_sans_ext(basename(zip_file))
  # Assign the result of loadSQM() to a variable with the extracted name
  assign(obj_name, loadSQM(zip_file), envir = .GlobalEnv)
}

##selecting my R objects that start with these 2 capital letters
object_names <- ls(pattern = "^[LW]")
object_names

# Define the list of fungal phyla
fungal_phyla <- c("Ascomycota", "Basidiomycota", "Chytridiomycota", "Microsporidia", "Mucoromycota", "Zoopagomycota", "Olpidiomycota")

for (obj in object_names) {
  # Construct the new variable name
  new_name <- paste0(obj, ".fun")
  # Retrieve the object
  obj_data <- get(obj)
  # Extract phylum names from the SQM structure
  existing_phyla <- rownames(obj_data[["taxa"]][["phylum"]]$abun)  # Extract row names (phylum names)
  # Find which fungal phyla are present
  valid_fungal_phyla <- intersect(fungal_phyla, existing_phyla)
  # Print debugging information
  print(paste("Processing:", obj, "→", new_name))
  print(paste("Valid phyla found:", paste(valid_fungal_phyla, collapse = ", ")))
  # Only proceed if there are valid fungal phyla
  if (length(valid_fungal_phyla) > 0) {
    result <- subsetTaxMulti(obj_data, "phylum", valid_fungal_phyla)
  } else {
    result <- NULL  # Or handle empty cases differently
    message(paste("No fungal phyla found in", obj))
  }
  
  # Assign result to a new variable
  assign(new_name, result, envir = .GlobalEnv)
}

# Get all objects that end with ".fun" (matching our dynamically created ones)
fun_objects <- ls(pattern = "\\.fun$")

# Retrieve the actual objects using mget()
fun_list <- mget(fun_objects)

# Combine them into one using combineSQMlite()
funtab.allsamps <- do.call(combineSQMlite, fun_list)

saveRDS(funtab.allsamps, file="funtab.allsamps.rds")
```

Worked locally but didn't work on the cluster, so I assume one or more of the samples were troublesome

No fungal phyla found in WL7
No fungal phyla found in WL8

```{r}
funtab1 <- readRDS("../SQM_zips/funtab.allsamps.rds")

funtab <- funtab1[["functions"]][["KEGG"]]$abund

#write.csv(funtab,file="funtab.counts.csv")
```
